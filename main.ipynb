{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e872db00-b51c-4dfb-a92c-9e75607de53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جميع المكتبات تم تثبيتها بنجاح!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import cvzone\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"جميع المكتبات تم تثبيتها بنجاح!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e072e4cd-4a64-456b-98aa-501df46c1fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d203fd8-c71a-449e-b92c-952808c3d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/10/01 05:14:35] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='C:\\\\Users\\\\makany\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "################################\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize PaddleOCR for license plate recognition\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "# Load YOLOv8 model for vehicle detection\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('car.mp4')\n",
    "\n",
    "# Define the region of interest (ROI) for the traffic light\n",
    "traffic_light_roi = (900, 100, 960, 160)  # Example values\n",
    "\n",
    "# To track recognized plates\n",
    "processed_numbers = set()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for consistency\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # Detect vehicles using YOLOv8\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    # Process results from YOLOv8\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # Get the box object\n",
    "        \n",
    "        for box in boxes:  # Iterate over detected boxes\n",
    "            # Get the bounding box details; box.xyxy contains x1, y1, x2, y2\n",
    "            x1, y1, x2, y2 = box.xyxy[0]  # Unpack coordinates\n",
    "            conf = box.conf[0]  # Get the confidence score\n",
    "            cls = int(box.cls[0])  # Get the class ID\n",
    "            \n",
    "            # Check if the detected object is a vehicle (adjust class IDs as needed)\n",
    "            if cls in [0, 2, 3]:  # Example class IDs for vehicles\n",
    "                # Implement logic to check if vehicle is in violation\n",
    "                traffic_light_status = \"Red\"  # Assuming red light for this example\n",
    "\n",
    "                if traffic_light_status == \"Red\":\n",
    "                    # Crop the detected region (license plate)\n",
    "                    crop = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "\n",
    "                    # Apply OCR to the cropped image\n",
    "                    ocr_result = ocr.ocr(crop, cls=True)\n",
    "                    if ocr_result and len(ocr_result) > 0:\n",
    "                        text = ocr_result[0][0][1][0].strip()\n",
    "                        print(\"ewwwwwwwwwww\",text)\n",
    "\n",
    "                        # Log recognized plate if valid and not processed before\n",
    "                        if text and len(text) > 4 and text not in processed_numbers:\n",
    "                            processed_numbers.add(text)\n",
    "                            current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                            print(f\"Recognized License Plate: {text} at {current_datetime}\")\n",
    "\n",
    "                            # Optionally, save to a file\n",
    "                            with open(\"car_plate_data.txt\", \"a\") as file:\n",
    "                                file.write(f\"{text}\\t{current_datetime}\\tRed light violation\\n\")\n",
    "\n",
    "                    # Draw a rectangle around the detected license plate\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw the traffic light ROI\n",
    "    cv2.rectangle(frame, (traffic_light_roi[0], traffic_light_roi[1]),\n",
    "                  (traffic_light_roi[2], traffic_light_roi[3]), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Press 'Esc' key to exit\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ecd8739-7ac8-4a10-b087-0f27910e5f17",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3851466684.py, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 54\u001b[1;36m\u001b[0m\n\u001b[1;33m    for plate_result in plate_results:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the YOLO models\n",
    "plate_model = YOLO(\"best.pt\")  # Model for license plate detection\n",
    "model = YOLO(\"yolov8n.pt\")  # Model for general object detection\n",
    "\n",
    "# Initialize PaddleOCR for license plate recognition\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('car.mp4')\n",
    "\n",
    "# Define the region of interest (ROI) for the traffic light\n",
    "traffic_light_roi = (900, 100, 960, 160)  # Example values\n",
    "\n",
    "# To track recognized plates\n",
    "processed_numbers = set()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for consistency\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # Detect objects (e.g., vehicles) using the general YOLO model\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    # Process the detection results from the general YOLO model\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        \n",
    "        for box in boxes:\n",
    "            # Get the bounding box details\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            conf = box.conf[0]\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            # Check if the detected object is a vehicle (adjust class IDs as needed)\n",
    "            if cls in [0, 2, 3]:  # Example class IDs for vehicles\n",
    "                traffic_light_status = \"Red\"  # Assuming red light for this example\n",
    "\n",
    "                if traffic_light_status == \"Red\":\n",
    "                    # Detect license plates on the cropped region using the plate_model\n",
    "                    vehicle_crop = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "                    plate_results = plate_model(vehicle_crop, stream=True)\n",
    "                cv2.imshow(\"dsfsfsdf\",vehicle_crop)\n",
    "                    # Process license plate detection results\n",
    "                    for plate_result in plate_results:\n",
    "                        plate_boxes = plate_result.boxes\n",
    "\n",
    "                        for plate_box in plate_boxes:\n",
    "                            # Get license plate bounding box details\n",
    "                            px1, py1, px2, py2 = plate_box.xyxy[0]\n",
    "\n",
    "                            # Crop the detected region (license plate)\n",
    "                            plate_crop = vehicle_crop[int(py1):int(py2), int(px1):int(px2)]\n",
    "\n",
    "                            # Apply OCR to the cropped image\n",
    "                            ocr_result = ocr.ocr(plate_crop, cls=True)\n",
    "                            if ocr_result and len(ocr_result) > 0:\n",
    "                                text = ocr_result[0][0][1][0].strip()\n",
    "\n",
    "                                # Log recognized plate if valid and not processed before\n",
    "                                if text and len(text) > 4 and text not in processed_numbers:\n",
    "                                    processed_numbers.add(text)\n",
    "                                    current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                                    print(f\"Recognized License Plate: {text} at {current_datetime}\")\n",
    "\n",
    "                                    # Optionally, save to a file\n",
    "                                    with open(\"car_plate_data.txt\", \"a\") as file:\n",
    "                                        file.write(f\"{text}\\t{current_datetime}\\tRed light violation\\n\")\n",
    "\n",
    "                            # Draw a rectangle around the detected license plate\n",
    "                            cv2.rectangle(frame, (int(px1), int(py1)), (int(px2), int(py2)), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw the traffic light ROI\n",
    "    cv2.rectangle(frame, (traffic_light_roi[0], traffic_light_roi[1]),\n",
    "                  (traffic_light_roi[2], traffic_light_roi[3]), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Press 'Esc' key to exit\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ebe34c-c8bf-487a-bdb4-ade8f07d5f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/09/30 18:05:15] ppocr DEBUG: Namespace(alpha=1.0, alphacolor=(255, 255, 255), benchmark=False, beta=1.0, binarize=False, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_box_type='quad', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, fourier_degree=5, gpu_id=0, gpu_mem=500, help='==SUPPRESS==', image_dir=None, image_orientation=False, invert=False, ir_optim=True, kie_algorithm='LayoutXLM', label_list=['0', '180'], lang='en', layout=True, layout_dict_path=None, layout_model_dir=None, layout_nms_threshold=0.5, layout_score_threshold=0.5, max_batch_size=10, max_text_length=25, merge_no_span_structure=True, min_subgraph_size=15, mode='structure', ocr=True, ocr_order_method=None, ocr_version='PP-OCRv4', output='./output', page_num=0, precision='fp32', process_id=0, re_model_dir=None, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='C:\\\\Users\\\\makany\\\\anaconda3\\\\envs\\\\ML3\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', recovery=False, return_word_box=False, save_crop_res=False, save_log_path='./log_output/', savefile=False, scales=[8, 16, 32], ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ser_model_dir=None, show_log=True, sr_batch_num=1, sr_image_shape='3, 32, 128', sr_model_dir=None, structure_version='PP-StructureV2', table=True, table_algorithm='TableAttn', table_char_dict_path=None, table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=True, use_dilation=False, use_gpu=False, use_mlu=False, use_mp=False, use_npu=False, use_onnx=False, use_pdf2docx_api=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_visual_backbone=True, use_xpu=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n",
      "\n",
      "0: 416x640 5 cars, 4 traffic lights, 97.9ms\n",
      "\n",
      "0: 480x640 1 License_Plate, 132.9ms\n",
      "[2024/09/30 18:05:18] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.023988008499145508\n",
      "[2024/09/30 18:05:18] ppocr DEBUG: cls num  : 0, elapsed : 0\n",
      "[2024/09/30 18:05:18] ppocr DEBUG: rec_res num  : 0, elapsed : 0.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 71\u001b[0m\n\u001b[0;32m     69\u001b[0m ocr_result \u001b[38;5;241m=\u001b[39m ocr\u001b[38;5;241m.\u001b[39mocr(plate_crop, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ocr_result \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ocr_result) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 71\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mocr_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# Log recognized plate if valid and not processed before\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m text \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_numbers:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the YOLO models\n",
    "plate_model = YOLO(\"best.pt\")  # Model for license plate detection\n",
    "model = YOLO(\"yolov8n.pt\")  # Model for general object detection\n",
    "\n",
    "# Initialize PaddleOCR for license plate recognition\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('car.mp4')\n",
    "\n",
    "# Define the region of interest (ROI) for the traffic light\n",
    "traffic_light_roi = (900, 100, 960, 160)  # Example values\n",
    "\n",
    "# To track recognized plates\n",
    "processed_numbers = set()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for consistency\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # Detect objects (e.g., vehicles) using the general YOLO model\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    # Process the detection results from the general YOLO model\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        \n",
    "        for box in boxes:\n",
    "            # Get the bounding box details\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            conf = box.conf[0]\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            # Check if the detected object is a vehicle (adjust class IDs as needed)\n",
    "            if cls in [0, 2, 3]:  # Example class IDs for vehicles\n",
    "                traffic_light_status = \"Red\"  # Assuming red light for this example\n",
    "\n",
    "                if traffic_light_status == \"Red\":\n",
    "                    # Detect license plates on the cropped region using the plate_model\n",
    "                    vehicle_crop = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "                    \n",
    "                    # Display the cropped vehicle for visual verification\n",
    "                    cv2.imshow(\"Vehicle Crop\", vehicle_crop)\n",
    "\n",
    "                    plate_results = plate_model(vehicle_crop, stream=True)\n",
    "\n",
    "                    # Process license plate detection results\n",
    "                    for plate_result in plate_results:\n",
    "                        plate_boxes = plate_result.boxes\n",
    "\n",
    "                        for plate_box in plate_boxes:\n",
    "                            # Get license plate bounding box details\n",
    "                            px1, py1, px2, py2 = plate_box.xyxy[0]\n",
    "\n",
    "                            # Crop the detected region (license plate)\n",
    "                            plate_crop = vehicle_crop[int(py1):int(py2), int(px1):int(px2)]\n",
    "\n",
    "                            # Apply OCR to the cropped image\n",
    "                            ocr_result = ocr.ocr(plate_crop, cls=True)\n",
    "                            if ocr_result and len(ocr_result) > 0:\n",
    "                                text = ocr_result[0][0][1][0].strip()\n",
    "\n",
    "                                # Log recognized plate if valid and not processed before\n",
    "                                if text and len(text) > 4 and text not in processed_numbers:\n",
    "                                    processed_numbers.add(text)\n",
    "                                    current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                                    print(f\"Recognized License Plate: {text} at {current_datetime}\")\n",
    "\n",
    "                                    # Optionally, save to a file\n",
    "                                    with open(\"car_plate_data.txt\", \"a\") as file:\n",
    "                                        file.write(f\"{text}\\t{current_datetime}\\tRed light violation\\n\")\n",
    "\n",
    "                            # Draw a rectangle around the detected license plate\n",
    "                            cv2.rectangle(vehicle_crop, (int(px1), int(py1)), (int(px2), int(py2)), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw the traffic light ROI\n",
    "    cv2.rectangle(frame, (traffic_light_roi[0], traffic_light_roi[1]),\n",
    "                  (traffic_light_roi[2], traffic_light_roi[3]), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Press 'Esc' key to exit\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "###############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "797c4aaf-8d64-48be-aa26-e67404b06dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/10/01 18:24:54] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='C:\\\\Users\\\\makany\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 94.9ms\n",
      "Speed: 6.0ms preprocess, 94.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 109.9ms\n",
      "Speed: 13.0ms preprocess, 109.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 94.9ms\n",
      "Speed: 4.0ms preprocess, 94.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 91.9ms\n",
      "Speed: 4.0ms preprocess, 91.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 92.9ms\n",
      "Speed: 4.0ms preprocess, 92.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 91.9ms\n",
      "Speed: 4.0ms preprocess, 91.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 92.9ms\n",
      "Speed: 4.0ms preprocess, 92.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 90.9ms\n",
      "Speed: 3.0ms preprocess, 90.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 92.9ms\n",
      "Speed: 4.0ms preprocess, 92.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 90.9ms\n",
      "Speed: 4.0ms preprocess, 90.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 88.9ms\n",
      "Speed: 4.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 86.9ms\n",
      "Speed: 5.0ms preprocess, 86.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 88.9ms\n",
      "Speed: 5.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 98.9ms\n",
      "Speed: 5.0ms preprocess, 98.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 2 traffic lights, 75.0ms\n",
      "Speed: 3.0ms preprocess, 75.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 117.9ms\n",
      "Speed: 3.0ms preprocess, 117.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 121.9ms\n",
      "Speed: 18.0ms preprocess, 121.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 87.9ms\n",
      "Speed: 4.0ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 92.9ms\n",
      "Speed: 4.0ms preprocess, 92.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 92.0ms\n",
      "Speed: 5.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 89.0ms\n",
      "Speed: 5.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 85.9ms\n",
      "Speed: 4.0ms preprocess, 85.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 90.9ms\n",
      "Speed: 5.0ms preprocess, 90.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 86.9ms\n",
      "Speed: 4.0ms preprocess, 86.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 88.9ms\n",
      "Speed: 4.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 91.0ms\n",
      "Speed: 5.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 4.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 77.0ms\n",
      "Speed: 3.0ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 3.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 4.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 76.9ms\n",
      "Speed: 3.0ms preprocess, 76.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 3.0ms preprocess, 78.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 77.0ms\n",
      "Speed: 3.0ms preprocess, 77.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 3.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 126.9ms\n",
      "Speed: 3.0ms preprocess, 126.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 127.9ms\n",
      "Speed: 5.0ms preprocess, 127.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 87.9ms\n",
      "Speed: 5.0ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 3.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 85.9ms\n",
      "Speed: 3.0ms preprocess, 85.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 87.0ms\n",
      "Speed: 4.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 90.9ms\n",
      "Speed: 4.0ms preprocess, 90.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 89.9ms\n",
      "Speed: 4.0ms preprocess, 89.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 88.9ms\n",
      "Speed: 4.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 90.9ms\n",
      "Speed: 4.0ms preprocess, 90.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 89.9ms\n",
      "Speed: 4.0ms preprocess, 89.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 87.9ms\n",
      "Speed: 3.0ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 90.9ms\n",
      "Speed: 4.0ms preprocess, 90.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 86.9ms\n",
      "Speed: 4.0ms preprocess, 86.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 87.9ms\n",
      "Speed: 5.0ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 89.9ms\n",
      "Speed: 4.0ms preprocess, 89.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 93.9ms\n",
      "Speed: 51.0ms preprocess, 93.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 5.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 85.9ms\n",
      "Speed: 5.0ms preprocess, 85.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 83.9ms\n",
      "Speed: 3.0ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 80.9ms\n",
      "Speed: 3.0ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 5.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 97.9ms\n",
      "Speed: 4.0ms preprocess, 97.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 92.9ms\n",
      "Speed: 4.0ms preprocess, 92.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 1 bus, 3 traffic lights, 97.9ms\n",
      "Speed: 3.0ms preprocess, 97.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 87.9ms\n",
      "Speed: 4.0ms preprocess, 87.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 79.9ms\n",
      "Speed: 4.0ms preprocess, 79.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 87.9ms\n",
      "Speed: 4.0ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 77.0ms\n",
      "Speed: 2.0ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 4.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 3 traffic lights, 85.9ms\n",
      "Speed: 4.0ms preprocess, 85.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 3 traffic lights, 89.0ms\n",
      "Speed: 4.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 77.9ms\n",
      "Speed: 4.0ms preprocess, 77.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 4.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 79.9ms\n",
      "Speed: 4.0ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 5.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 88.9ms\n",
      "Speed: 4.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 132.9ms\n",
      "Speed: 3.0ms preprocess, 132.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 4.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 3.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 3.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 78.9ms\n",
      "Speed: 4.0ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 89.0ms\n",
      "Speed: 3.0ms preprocess, 89.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 2.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 84.9ms\n",
      "Speed: 4.0ms preprocess, 84.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 3.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 131.9ms\n",
      "Speed: 4.0ms preprocess, 131.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 77.0ms\n",
      "Speed: 3.0ms preprocess, 77.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 5.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 3.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 2.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 3.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 5.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 5.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.9ms\n",
      "Speed: 3.0ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 4.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 3.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 3.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 3.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 4.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 4.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 99.9ms\n",
      "Speed: 37.0ms preprocess, 99.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.9ms\n",
      "Speed: 3.0ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 78.0ms\n",
      "Speed: 3.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 81.9ms\n",
      "Speed: 3.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 139.9ms\n",
      "Speed: 4.0ms preprocess, 139.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 80.9ms\n",
      "Speed: 3.0ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 83.9ms\n",
      "Speed: 4.0ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 81.0ms\n",
      "Speed: 3.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "## Test##\n",
    "\n",
    "\n",
    "import cvzone\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the YOLO models\n",
    "plate_model = YOLO(\"best.pt\")  # Model for license plate detection\n",
    "model = YOLO(\"yolov8n.pt\")  # Model for general object detection\n",
    "\n",
    "# Initialize PaddleOCR for license plate recognition\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('car.mp4')\n",
    "\n",
    "# Define the region of interest (ROI) for the traffic light\n",
    "traffic_light_roi = (900, 100, 960, 160)  # Example values\n",
    "\n",
    "# To track recognized plates\n",
    "processed_numbers = set()\n",
    "Traffic_color=\"\"\n",
    "po1_rec=(570 ,370)\n",
    "po12_rec=(176 ,370)\n",
    "\n",
    "width = 1020\n",
    "height = 720\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for consistency\n",
    "    frame = cv2.resize(frame, (1020, 720))\n",
    "\n",
    "    # Detect objects (e.g., vehicles) using the general YOLO model\n",
    "    results = model(frame, stream=True)\n",
    "    \n",
    "    black_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    cv2.line(frame,(po1_rec),(po12_rec),(255, 0, 0),2)\n",
    "\n",
    "    # Process the detection results from the general YOLO model\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        \n",
    "        for box in boxes:\n",
    "            # Get the bounding box details\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            \n",
    "            x, y, w, z = int(x1), int(y1), int(x2), int(y2)\n",
    "            w = w - x\n",
    "            h = z - y\n",
    "            cx = x + w // 2\n",
    "            cy = y + h // 2\n",
    "            conf = box.conf[0]\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            if cls == 9:  # Adjust class index as needed\n",
    "\n",
    "\n",
    "                # Draw on black_image\n",
    "\n",
    "                cvzone.cornerRect(frame, (x, y, w, h), colorR=False, colorC=(0, 0, 0))\n",
    "\n",
    "\n",
    "                cv2.rectangle(black_image, (x, y), (x + w, y + h), (255, 255, 255), -1)\n",
    "\n",
    "                # cv2.rectangle(frame, (x, y), (x + w, y + h // 3), (0, 0, 255), 2)\n",
    "                # cv2.rectangle(frame, (x, y + h // 3), (x + w, y + (h // 3) * 2), (0, 255, 255), 2)\n",
    "                # cv2.rectangle(frame, (x, y + (h // 3) * 2), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "            bitwise = cv2.bitwise_and(frame, black_image)\n",
    "\n",
    "            # Convert the frame to HSV color space\n",
    "\n",
    "            hsv_frame = cv2.cvtColor(bitwise, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "            gray_image = cv2.cvtColor(bitwise, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply thresholding to the grayscale image\n",
    "            _, canny_black_image = cv2.threshold(gray_image, 70, 250, cv2.THRESH_BINARY)\n",
    "\n",
    "            # kernel = np.ones((3, 3), np.uint8)\n",
    "            #\n",
    "            # # Apply dilation\n",
    "            # canny_black_image = cv2.dilate(canny_black_image, kernel)\n",
    "\n",
    "            if cv2.countNonZero(canny_black_image[y:y + h // 3, x:x + w]) > 20:\n",
    "                # Show the detected color on the frame\n",
    "                Traffic_color=\"Red\"\n",
    "            elif cv2.countNonZero(canny_black_image[y + h // 3:y + (h // 3) * 2, x:x + w]) > 20:\n",
    "                Traffic_color=\"Yellow\"\n",
    "\n",
    "            elif cv2.countNonZero(canny_black_image[y + (h // 3) * 2:y + h, x:x + w]) > 20:\n",
    "                Traffic_color = \"Green\"\n",
    "\n",
    "            cv2.putText(frame, f\"Traffic Light: {Traffic_color}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                        (255, 0, 255), 2)\n",
    "\n",
    "\n",
    "            if  Traffic_color==\"Red\" and 452 < cy < 455 and 90 < cx < 800:\n",
    "                # Detect license plates on the cropped region using the plate_model\n",
    "                vehicle_crop = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "                \n",
    "                # Display the cropped vehicle for visual verification\n",
    "                #cv2.imshow(\"Vehicle Crop\", vehicle_crop)\n",
    "\n",
    "                plate_results = plate_model(vehicle_crop, stream=True)\n",
    "\n",
    "                # Process license plate detection results\n",
    "                for plate_result in plate_results:\n",
    "                    plate_boxes = plate_result.boxes\n",
    "\n",
    "                    for plate_box in plate_boxes:\n",
    "                        # Get license plate bounding box details\n",
    "                        px1, py1, px2, py2 = plate_box.xyxy[0]\n",
    "\n",
    "                        # Crop the detected region (license plate)\n",
    "                        plate_crop = vehicle_crop[int(py1):int(py2), int(px1):int(px2)]\n",
    "\n",
    "                        # Apply OCR to the cropped image\n",
    "                        ocr_result = ocr.ocr(plate_crop, cls=True)\n",
    "                        if ocr_result and len(ocr_result) > 0:\n",
    "                            text = ocr_result[0][0][1][0].strip()\n",
    "\n",
    "                            # Log recognized plate if valid and not processed before\n",
    "                            if text and len(text) > 4 and text not in processed_numbers:\n",
    "                                processed_numbers.add(text)\n",
    "                                current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                                print(f\"Recognized License Plate: {text} at {current_datetime}\")\n",
    "\n",
    "                                # Optionally, save to a file\n",
    "                                with open(\"car_plate_data.txt\", \"a\") as file:\n",
    "                                    file.write(f\"{text}\\t{current_datetime}\\tRed light violation\\n\")\n",
    "\n",
    "                        # Draw a rectangle around the detected license plate\n",
    "                        cv2.rectangle(vehicle_crop, (int(px1), int(py1)), (int(px2), int(py2)), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw the traffic light ROI\n",
    "    cv2.rectangle(frame, (traffic_light_roi[0], traffic_light_roi[1]),\n",
    "                  (traffic_light_roi[2], traffic_light_roi[3]), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Press 'Esc' key to exit\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613c9de-bd3b-4d99-a31d-6b04ee9c46f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07c2f845-3293-4907-aa7e-63ce385dce89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/10/04 02:33:14] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='C:\\\\Users\\\\makany\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\makany/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 4015.2ms\n",
      "Speed: 251.3ms preprocess, 4015.2ms inference, 173.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 111.9ms\n",
      "Speed: 6.0ms preprocess, 111.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 89.9ms\n",
      "Speed: 3.0ms preprocess, 89.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 94.9ms\n",
      "Speed: 4.0ms preprocess, 94.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 95.9ms\n",
      "Speed: 3.0ms preprocess, 95.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 105.9ms\n",
      "Speed: 6.0ms preprocess, 105.9ms inference, 18.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 104.4ms\n",
      "Speed: 4.0ms preprocess, 104.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 105.9ms\n",
      "Speed: 4.0ms preprocess, 105.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 101.9ms\n",
      "Speed: 5.0ms preprocess, 101.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 113.0ms\n",
      "Speed: 4.0ms preprocess, 113.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 138.9ms\n",
      "Speed: 4.0ms preprocess, 138.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 133.0ms\n",
      "Speed: 3.0ms preprocess, 133.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 117.0ms\n",
      "Speed: 4.0ms preprocess, 117.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 109.9ms\n",
      "Speed: 6.0ms preprocess, 109.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 116.9ms\n",
      "Speed: 5.0ms preprocess, 116.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 115.9ms\n",
      "Speed: 5.0ms preprocess, 115.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 115.9ms\n",
      "Speed: 6.0ms preprocess, 115.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 128.9ms\n",
      "Speed: 6.0ms preprocess, 128.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 124.0ms\n",
      "Speed: 5.0ms preprocess, 124.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 2 traffic lights, 112.0ms\n",
      "Speed: 4.0ms preprocess, 112.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 115.9ms\n",
      "Speed: 4.0ms preprocess, 115.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 115.9ms\n",
      "Speed: 6.0ms preprocess, 115.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 101.9ms\n",
      "Speed: 5.0ms preprocess, 101.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 116.0ms\n",
      "Speed: 4.0ms preprocess, 116.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 125.0ms\n",
      "Speed: 3.0ms preprocess, 125.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 116.0ms\n",
      "Speed: 6.0ms preprocess, 116.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 117.0ms\n",
      "Speed: 6.0ms preprocess, 117.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 120.0ms\n",
      "Speed: 4.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 114.0ms\n",
      "Speed: 7.0ms preprocess, 114.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 125.0ms\n",
      "Speed: 4.0ms preprocess, 125.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 109.0ms\n",
      "Speed: 3.0ms preprocess, 109.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 102.9ms\n",
      "Speed: 4.0ms preprocess, 102.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 105.9ms\n",
      "Speed: 4.0ms preprocess, 105.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 113.9ms\n",
      "Speed: 5.0ms preprocess, 113.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 94.9ms\n",
      "Speed: 7.0ms preprocess, 94.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 105.9ms\n",
      "Speed: 3.0ms preprocess, 105.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 108.9ms\n",
      "Speed: 6.0ms preprocess, 108.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 98.0ms\n",
      "Speed: 4.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 99.0ms\n",
      "Speed: 3.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 98.1ms\n",
      "Speed: 4.0ms preprocess, 98.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 94.9ms\n",
      "Speed: 3.0ms preprocess, 94.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 95.1ms\n",
      "Speed: 4.0ms preprocess, 95.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 79.5ms\n",
      "Speed: 3.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 83.9ms\n",
      "Speed: 3.0ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 79.9ms\n",
      "Speed: 3.0ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 2.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 83.5ms\n",
      "Speed: 3.0ms preprocess, 83.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 82.9ms\n",
      "Speed: 3.0ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 79.5ms\n",
      "Speed: 4.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 83.9ms\n",
      "Speed: 3.0ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 85.9ms\n",
      "Speed: 3.0ms preprocess, 85.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 105.9ms\n",
      "Speed: 17.0ms preprocess, 105.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.5ms\n",
      "Speed: 3.0ms preprocess, 82.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.9ms\n",
      "Speed: 3.0ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 80.9ms\n",
      "Speed: 4.0ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 81.9ms\n",
      "Speed: 4.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 4.0ms preprocess, 80.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 81.9ms\n",
      "Speed: 4.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 81.9ms\n",
      "Speed: 4.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 3.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 3 traffic lights, 80.9ms\n",
      "Speed: 4.0ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 4.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.9ms\n",
      "Speed: 3.0ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 1 bus, 3 traffic lights, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 83.5ms\n",
      "Speed: 4.0ms preprocess, 83.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 87.9ms\n",
      "Speed: 3.0ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 84.9ms\n",
      "Speed: 3.0ms preprocess, 84.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 84.9ms\n",
      "Speed: 3.0ms preprocess, 84.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 3 traffic lights, 88.9ms\n",
      "Speed: 3.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 3 traffic lights, 126.0ms\n",
      "Speed: 4.0ms preprocess, 126.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 3 traffic lights, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 3 traffic lights, 85.9ms\n",
      "Speed: 3.0ms preprocess, 85.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 3 traffic lights, 106.9ms\n",
      "Speed: 39.0ms preprocess, 106.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 3.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 82.9ms\n",
      "Speed: 4.0ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 78.0ms\n",
      "Speed: 3.2ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 88.0ms\n",
      "Speed: 4.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 80.9ms\n",
      "Speed: 3.0ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 3 traffic lights, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 83.9ms\n",
      "Speed: 3.0ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.9ms\n",
      "Speed: 3.0ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 83.0ms\n",
      "Speed: 4.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 88.9ms\n",
      "Speed: 3.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 82.0ms\n",
      "Speed: 3.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 98.9ms\n",
      "Speed: 6.0ms preprocess, 98.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 102.0ms\n",
      "Speed: 5.0ms preprocess, 102.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 135.0ms\n",
      "Speed: 13.0ms preprocess, 135.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 97.0ms\n",
      "Speed: 3.0ms preprocess, 97.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 104.0ms\n",
      "Speed: 4.0ms preprocess, 104.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 111.9ms\n",
      "Speed: 3.5ms preprocess, 111.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 102.0ms\n",
      "Speed: 3.0ms preprocess, 102.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 103.0ms\n",
      "Speed: 5.0ms preprocess, 103.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 103.9ms\n",
      "Speed: 3.0ms preprocess, 103.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 103.0ms\n",
      "Speed: 5.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 112.9ms\n",
      "Speed: 3.0ms preprocess, 112.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 116.0ms\n",
      "Speed: 4.0ms preprocess, 116.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 118.1ms\n",
      "Speed: 4.0ms preprocess, 118.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 108.0ms\n",
      "Speed: 5.0ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 98.0ms\n",
      "Speed: 4.0ms preprocess, 98.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 103.0ms\n",
      "Speed: 3.0ms preprocess, 103.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 105.0ms\n",
      "Speed: 3.0ms preprocess, 105.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 109.0ms\n",
      "Speed: 4.0ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 111.0ms\n",
      "Speed: 3.0ms preprocess, 111.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 106.9ms\n",
      "Speed: 3.0ms preprocess, 106.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 107.0ms\n",
      "Speed: 3.0ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 108.0ms\n",
      "Speed: 4.0ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 95.0ms\n",
      "Speed: 3.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 125.0ms\n",
      "Speed: 26.0ms preprocess, 125.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 101.0ms\n",
      "Speed: 4.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 99.0ms\n",
      "Speed: 4.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 106.0ms\n",
      "Speed: 3.0ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 84.9ms\n",
      "Speed: 3.0ms preprocess, 84.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 85.0ms\n",
      "Speed: 2.0ms preprocess, 85.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.9ms\n",
      "Speed: 3.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.0ms\n",
      "Speed: 3.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 87.9ms\n",
      "Speed: 3.0ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 86.9ms\n",
      "Speed: 3.0ms preprocess, 86.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 81.5ms\n",
      "Speed: 3.0ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 85.9ms\n",
      "Speed: 3.0ms preprocess, 85.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 3 traffic lights, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 86.0ms\n",
      "Speed: 2.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 86.9ms\n",
      "Speed: 3.0ms preprocess, 86.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 83.0ms\n",
      "Speed: 5.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 90.5ms\n",
      "Speed: 6.0ms preprocess, 90.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 136.9ms\n",
      "Speed: 3.0ms preprocess, 136.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 140.9ms\n",
      "Speed: 4.0ms preprocess, 140.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 157.9ms\n",
      "Speed: 3.0ms preprocess, 157.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 146.9ms\n",
      "Speed: 4.0ms preprocess, 146.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 151.9ms\n",
      "Speed: 7.0ms preprocess, 151.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 163.0ms\n",
      "Speed: 5.0ms preprocess, 163.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 125.0ms\n",
      "Speed: 3.0ms preprocess, 125.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 134.0ms\n",
      "Speed: 3.0ms preprocess, 134.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 134.0ms\n",
      "Speed: 3.0ms preprocess, 134.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 125.0ms\n",
      "Speed: 3.0ms preprocess, 125.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 128.0ms\n",
      "Speed: 3.0ms preprocess, 128.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 126.0ms\n",
      "Speed: 3.0ms preprocess, 126.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 145.0ms\n",
      "Speed: 37.1ms preprocess, 145.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 132.0ms\n",
      "Speed: 5.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 106.2ms\n",
      "Speed: 5.0ms preprocess, 106.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 99.9ms\n",
      "Speed: 3.0ms preprocess, 99.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 99.9ms\n",
      "Speed: 5.0ms preprocess, 99.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 94.0ms\n",
      "Speed: 3.0ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 95.9ms\n",
      "Speed: 2.0ms preprocess, 95.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 99.0ms\n",
      "Speed: 5.0ms preprocess, 99.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 92.0ms\n",
      "Speed: 3.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 166.8ms\n",
      "Speed: 44.0ms preprocess, 166.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 95.0ms\n",
      "Speed: 4.0ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 89.9ms\n",
      "Speed: 5.0ms preprocess, 89.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 91.0ms\n",
      "Speed: 4.0ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 88.9ms\n",
      "Speed: 3.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 120.0ms\n",
      "Speed: 35.0ms preprocess, 120.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 92.0ms\n",
      "Speed: 3.0ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 115.9ms\n",
      "Speed: 2.0ms preprocess, 115.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 117.9ms\n",
      "Speed: 4.0ms preprocess, 117.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 124.9ms\n",
      "Speed: 3.0ms preprocess, 124.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 117.9ms\n",
      "Speed: 3.0ms preprocess, 117.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 89.9ms\n",
      "Speed: 2.0ms preprocess, 89.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 85.9ms\n",
      "Speed: 3.0ms preprocess, 85.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 86.9ms\n",
      "Speed: 3.0ms preprocess, 86.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 87.0ms\n",
      "Speed: 3.0ms preprocess, 87.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 176.9ms\n",
      "Speed: 2.0ms preprocess, 176.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 3 traffic lights, 86.0ms\n",
      "Speed: 14.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 3 traffic lights, 85.0ms\n",
      "Speed: 3.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 89.9ms\n",
      "Speed: 2.0ms preprocess, 89.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 88.9ms\n",
      "Speed: 3.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 83.0ms\n",
      "Speed: 3.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 98.9ms\n",
      "Speed: 36.0ms preprocess, 98.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 86.0ms\n",
      "Speed: 2.0ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 85.5ms\n",
      "Speed: 11.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 82.9ms\n",
      "Speed: 3.0ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 82.9ms\n",
      "Speed: 3.0ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 90.0ms\n",
      "Speed: 3.0ms preprocess, 90.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 85.2ms\n",
      "Speed: 3.0ms preprocess, 85.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 88.0ms\n",
      "Speed: 3.0ms preprocess, 88.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 85.0ms\n",
      "Speed: 2.0ms preprocess, 85.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 85.1ms\n",
      "Speed: 3.0ms preprocess, 85.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 90.9ms\n",
      "\n",
      "0: 480x640 1 License_Plate, 258.0ms\n",
      "[2024/10/04 02:34:24] ppocr DEBUG: dt_boxes num : 1, elapsed : 3.4537973403930664\n",
      "[2024/10/04 02:34:24] ppocr DEBUG: cls num  : 1, elapsed : 0.42376089096069336\n",
      "[2024/10/04 02:34:25] ppocr DEBUG: rec_res num  : 1, elapsed : 0.5915663242340088\n",
      "Recognized License Plate: RKISYUH at 2024-10-04 02:34:25\n",
      "Speed: 3.0ms preprocess, 258.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Speed: 3.0ms preprocess, 90.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 166.9ms\n",
      "\n",
      "0: 512x640 1 License_Plate, 145.9ms\n",
      "[2024/10/04 02:34:27] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.009994029998779297\n",
      "[2024/10/04 02:34:27] ppocr DEBUG: cls num  : 1, elapsed : 0.007995843887329102\n",
      "[2024/10/04 02:34:27] ppocr DEBUG: rec_res num  : 1, elapsed : 0.09894537925720215\n",
      "Speed: 4.0ms preprocess, 145.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Speed: 5.0ms preprocess, 166.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cars, 2 traffic lights, 149.9ms\n",
      "\n",
      "0: 512x640 1 License_Plate, 143.9ms\n",
      "[2024/10/04 02:34:27] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.009994268417358398\n",
      "[2024/10/04 02:34:27] ppocr DEBUG: cls num  : 1, elapsed : 0.008995294570922852\n",
      "[2024/10/04 02:34:27] ppocr DEBUG: rec_res num  : 1, elapsed : 0.09595608711242676\n",
      "Speed: 3.0ms preprocess, 143.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Speed: 4.0ms preprocess, 149.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 203.5ms\n",
      "\n",
      "0: 512x640 1 License_Plate, 137.9ms\n",
      "[2024/10/04 02:34:28] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.009993553161621094\n",
      "[2024/10/04 02:34:28] ppocr DEBUG: cls num  : 1, elapsed : 0.007994890213012695\n",
      "[2024/10/04 02:34:28] ppocr DEBUG: rec_res num  : 1, elapsed : 0.09223246574401855\n",
      "Speed: 3.0ms preprocess, 137.9ms inference, 1.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Speed: 3.0ms preprocess, 203.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 149.9ms\n",
      "Speed: 4.0ms preprocess, 149.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 143.9ms\n",
      "Speed: 3.0ms preprocess, 143.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 144.9ms\n",
      "Speed: 4.0ms preprocess, 144.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 141.9ms\n",
      "Speed: 3.0ms preprocess, 141.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 139.9ms\n",
      "Speed: 3.0ms preprocess, 139.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 141.9ms\n",
      "Speed: 4.0ms preprocess, 141.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 140.9ms\n",
      "Speed: 4.0ms preprocess, 140.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 188.9ms\n",
      "Speed: 3.0ms preprocess, 188.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 141.9ms\n",
      "Speed: 3.0ms preprocess, 141.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 139.1ms\n",
      "Speed: 3.0ms preprocess, 139.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 140.9ms\n",
      "Speed: 3.0ms preprocess, 140.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 138.9ms\n",
      "Speed: 4.0ms preprocess, 138.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 142.9ms\n",
      "Speed: 3.0ms preprocess, 142.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 144.0ms\n",
      "Speed: 3.0ms preprocess, 144.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 140.5ms\n",
      "Speed: 4.0ms preprocess, 140.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 137.9ms\n",
      "Speed: 3.0ms preprocess, 137.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 139.9ms\n",
      "Speed: 3.0ms preprocess, 139.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 2 traffic lights, 141.9ms\n",
      "Speed: 3.0ms preprocess, 141.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 146.9ms\n",
      "Speed: 3.0ms preprocess, 146.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 140.9ms\n",
      "Speed: 3.0ms preprocess, 140.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 155.9ms\n",
      "Speed: 3.0ms preprocess, 155.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 139.9ms\n",
      "Speed: 4.0ms preprocess, 139.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 140.9ms\n",
      "Speed: 4.0ms preprocess, 140.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 2 traffic lights, 145.8ms\n",
      "Speed: 4.0ms preprocess, 145.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 143.9ms\n",
      "Speed: 4.0ms preprocess, 143.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 138.3ms\n",
      "Speed: 4.0ms preprocess, 138.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 145.7ms\n",
      "Speed: 3.0ms preprocess, 145.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 138.9ms\n",
      "Speed: 4.0ms preprocess, 138.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 2 traffic lights, 144.9ms\n",
      "Speed: 3.0ms preprocess, 144.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 1 train, 2 traffic lights, 142.4ms\n",
      "Speed: 3.0ms preprocess, 142.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 cars, 1 train, 2 traffic lights, 139.9ms\n",
      "Speed: 4.0ms preprocess, 139.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 2 traffic lights, 136.9ms\n",
      "Speed: 3.0ms preprocess, 136.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 cars, 1 train, 2 traffic lights, 137.9ms\n",
      "Speed: 4.0ms preprocess, 137.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 1 train, 2 traffic lights, 156.2ms\n",
      "Speed: 4.0ms preprocess, 156.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 1 train, 2 traffic lights, 144.9ms\n",
      "Speed: 3.0ms preprocess, 144.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 1 train, 2 traffic lights, 141.9ms\n",
      "Speed: 4.0ms preprocess, 141.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 cars, 1 train, 2 traffic lights, 137.8ms\n",
      "Speed: 3.0ms preprocess, 137.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 1 train, 2 traffic lights, 137.5ms\n",
      "Speed: 4.0ms preprocess, 137.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 cars, 1 train, 2 traffic lights, 142.9ms\n",
      "Speed: 4.0ms preprocess, 142.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 cars, 1 train, 2 traffic lights, 146.9ms\n",
      "Speed: 4.0ms preprocess, 146.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 cars, 1 train, 2 traffic lights, 137.9ms\n",
      "Speed: 3.0ms preprocess, 137.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 cars, 1 train, 2 traffic lights, 137.9ms\n",
      "Speed: 4.0ms preprocess, 137.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 cars, 1 train, 2 traffic lights, 137.9ms\n",
      "Speed: 4.0ms preprocess, 137.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 cars, 2 traffic lights, 146.9ms\n",
      "Speed: 4.0ms preprocess, 146.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 cars, 1 train, 2 traffic lights, 212.6ms\n",
      "Speed: 3.0ms preprocess, 212.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "## Test##\n",
    "\n",
    "\n",
    "import cvzone\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from paddleocr import PaddleOCR\n",
    "from datetime import datetime\n",
    "import requests\n",
    "\n",
    "# Load the YOLO models\n",
    "plate_model = YOLO(\"best.pt\")  # Model for license plate detection\n",
    "model = YOLO(\"yolov8n.pt\")  # Model for general object detection\n",
    "\n",
    "# Initialize PaddleOCR for license plate recognition\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture('car.mp4')\n",
    "\n",
    "# Define the region of interest (ROI) for the traffic light\n",
    "traffic_light_roi = (900, 100, 960, 160)  # Example values\n",
    "\n",
    "# To track recognized plates\n",
    "processed_numbers = set()\n",
    "po1_rec=(570 ,370)\n",
    "po12_rec=(176 ,370)\n",
    "Traffic_color=\"\"\n",
    "width = 1020\n",
    "height = 720\n",
    "\n",
    "# Telegram Bot Token and Chat ID\n",
    "TOKEN = \"7581663246:AAFNYv6F2JRjPkB-5VtIIIO-zue2SVYysAA\"\n",
    "\n",
    "chat_id = \"1347052266\"\n",
    "\n",
    "image_path = \"violation_licence.jpg\"\n",
    "image_path1 = \"violation_car.jpg\"\n",
    "\n",
    "\n",
    "def Send_Image(bot_token, chat_id, image):\n",
    "    \"\"\"\n",
    "    Sends an image to a Telegram chat.\n",
    "\n",
    "    Parameters:\n",
    "    - bot_token: The token for the Telegram bot.\n",
    "    - chat_id: The ID of the Telegram chat to send the image to.\n",
    "    - image: The file path of the image to send.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f'https://api.telegram.org/bot{bot_token}/sendPhoto'\n",
    "    files = {'photo': open(image, 'rb')}\n",
    "    data = {'chat_id': chat_id}\n",
    "    response = requests.post(url, files=files, data=data)\n",
    "    return response.json()\n",
    "\n",
    "def send_image_and_treatment(annotated_image_path, clean_text):\n",
    "    \"\"\"\n",
    "    Send image and treatment information to Telegram.\n",
    "\n",
    "    Parameters:\n",
    "    - annotated_image_path: The path to the annotated image.\n",
    "    - detected_diseases: A list of detected diseases and their treatments.\n",
    "    \"\"\"\n",
    "    Send_Image(TOKEN, chat_id, annotated_image_path)\n",
    "    \n",
    "    message = f\"this number: {clean_text}\"\n",
    "    url = f'https://api.telegram.org/bot{TOKEN}/sendMessage'\n",
    "    data = {'chat_id': chat_id, 'text': message}\n",
    "    requests.post(url, data=data)\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize the frame for consistency\n",
    "    frame = cv2.resize(frame, (1020, 720))\n",
    "\n",
    "    # Detect objects (e.g., vehicles) using the general YOLO model\n",
    "    results = model(frame, stream=True)\n",
    "    \n",
    "    black_image = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    cv2.line(frame,(po1_rec),(po12_rec),(255, 0, 0),2)\n",
    "\n",
    "    # Process the detection results from the general YOLO model\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        \n",
    "        for box in boxes:\n",
    "            # Get the bounding box details\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            \n",
    "            x, y, w, z = int(x1), int(y1), int(x2), int(y2)\n",
    "            w = w - x\n",
    "            h = z - y\n",
    "            cx = x + w // 2\n",
    "            cy = y + h // 2\n",
    "            conf = box.conf[0]\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            if cls == 9:  # Adjust class index as needed\n",
    "\n",
    "\n",
    "                # Draw on black_image\n",
    "\n",
    "                cvzone.cornerRect(frame, (x, y, w, h), colorR=False, colorC=(0, 0, 0))\n",
    "\n",
    "\n",
    "                cv2.rectangle(black_image, (x, y), (x + w, y + h), (255, 255, 255), -1)\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "            bitwise = cv2.bitwise_and(frame, black_image)\n",
    "\n",
    "            # Convert the frame to HSV color space\n",
    "\n",
    "            hsv_frame = cv2.cvtColor(bitwise, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "            gray_image = cv2.cvtColor(bitwise, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply thresholding to the grayscale image\n",
    "            _, canny_black_image = cv2.threshold(gray_image, 70, 250, cv2.THRESH_BINARY)\n",
    "\n",
    "            \n",
    "\n",
    "            if cv2.countNonZero(canny_black_image[y:y + h // 3, x:x + w]) >20 :\n",
    "                # Show the detected color on the frame\n",
    "                Traffic_color=\"Red\"\n",
    "\n",
    "                \n",
    "            elif cv2.countNonZero(canny_black_image[y + h // 3:y + (h // 3) * 2, x:x + w]) > 20:\n",
    "                Traffic_color=\"Yellow\"\n",
    "\n",
    "            elif cv2.countNonZero(canny_black_image[y + (h // 3) * 2:y + h, x:x + w]) > 20:\n",
    "                Traffic_color = \"Green\"\n",
    "\n",
    "            cv2.putText(frame, f\"Traffic Light: {Traffic_color}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                        (255, 0, 255), 2)\n",
    "\n",
    "\n",
    "            if  Traffic_color==\"Red\" and 452 < cy < 455 and 90 < cx < 800:\n",
    "                \n",
    "                # Detect license plates on the cropped region using the plate_model\n",
    "                vehicle_crop = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "                cv2.imwrite(image_path1,vehicle_crop )\n",
    "                \n",
    "                \n",
    "                # Display the cropped vehicle for visual verification\n",
    "                #cv2.imshow(\"Vehicle Crop\", vehicle_crop)\n",
    "\n",
    "                plate_results = plate_model(vehicle_crop, stream=True)\n",
    "\n",
    "                # Process license plate detection results\n",
    "                for plate_result in plate_results:\n",
    "                    plate_boxes = plate_result.boxes\n",
    "\n",
    "                    for plate_box in plate_boxes:\n",
    "                        # Get license plate bounding box details\n",
    "                        px1, py1, px2, py2 = plate_box.xyxy[0]\n",
    "\n",
    "                        # Crop the detected region (license plate)\n",
    "                        plate_crop = vehicle_crop[int(py1):int(py2), int(px1):int(px2)]\n",
    "\n",
    "                        cv2.imwrite(image_path,plate_crop)\n",
    "\n",
    "\n",
    "                        # Apply OCR to the cropped image\n",
    "                        ocr_result = ocr.ocr(plate_crop, cls=True)\n",
    "                        if ocr_result and len(ocr_result) > 0:\n",
    "                            text = ocr_result[0][0][1][0].strip()\n",
    "\n",
    "                            # Log recognized plate if valid and not processed befor\n",
    "\n",
    "                            if text:\n",
    "                                text_clean = text.replace(\" \", \"\").strip()\n",
    "                            else:\n",
    "                                text_clean = \"\"\n",
    "                            \n",
    "                            # تحقق من صحة النص وتنظيفه قبل المعالجة\n",
    "                            if text_clean and len(text_clean) > 4 and text_clean not in processed_numbers:\n",
    "                                processed_numbers.add(text_clean)  # أضف النص النظيفة إلى المجموعة لتتبعها\n",
    "                                current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                                print(f\"Recognized License Plate: {text_clean} at {current_datetime}\")\n",
    "\n",
    "                                # حفظ البيانات في الملف بدون فراغات\n",
    "                                with open(\"car_plate_data.txt\", \"a\") as file:\n",
    "                                    Send_Image(TOKEN,chat_id,image_path1)\n",
    "                                    send_image_and_treatment(image_path, text_clean)\n",
    "                                    \n",
    "                                    file.write(f\"{text_clean}\\t{current_datetime}\\tRed light violation\\n\")\n",
    "\n",
    "\n",
    "                        # Draw a rectangle around the detected license plate\n",
    "                        cv2.rectangle(vehicle_crop, (int(px1), int(py1)), (int(px2), int(py2)), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw the traffic light ROI\n",
    "    cv2.rectangle(frame, (traffic_light_roi[0], traffic_light_roi[1]),\n",
    "                  (traffic_light_roi[2], traffic_light_roi[3]), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Press 'Esc' key to exit\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb55edf0-badb-4b30-9d92-3e1ba3df882b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
